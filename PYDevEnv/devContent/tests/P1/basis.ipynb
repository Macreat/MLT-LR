{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PARCIAL 1 TAM (Teor√≠a de Aprendizaje de M√°quina)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ej 1 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dado el modelo de regresion : \n",
        "\n",
        "tn = \n",
        "ùúô\n",
        "(\n",
        "ùë•\n",
        "ùëõ\n",
        ")\n",
        "‚ä§\n",
        "ùë§\n",
        "+\n",
        "ùúÇ\n",
        "ùëõ\n",
        "t \n",
        "n\n",
        "‚Äã\n",
        " =œï(x \n",
        "n\n",
        "‚Äã\n",
        " ) \n",
        "‚ä§\n",
        " w+Œ∑ \n",
        "n\n",
        "‚Äã\n",
        " , con \n",
        "ùúÇ\n",
        "ùëõ\n",
        "‚àº\n",
        "ùëÅ\n",
        "(\n",
        "0\n",
        ",\n",
        "ùúé\n",
        "2\n",
        ")\n",
        "Œ∑ \n",
        "n\n",
        "‚Äã\n",
        " ‚àºN(0,œÉ \n",
        "2\n",
        " )\n",
        "\n",
        "\n",
        "Presentamos la inferencia o problema de optimizaci√≥n para los siguientes casos asumiendo datos i.i.d : \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### M√çNIMOS CUADRADOS (OLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### M√çNIMOS CUADRADOS REGULARIZADOS "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### M√ÅXIMA VEROSIMILITUD "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### M√ÅXIMO A POSTERIORI (MAP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MODELO BAYESIANO LINEAL GAUSSIANO "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### REGRESI√ìN R√çGIDA KERNEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PROCESOS GAUSIANOS (GP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Finalmente discutimos similitudes y diferencias:  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EJ 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Presentamos un cuadro comparativo de los siguientes regresores, en donde se discute el modelo matem atico, funcion de costo, estrategia\n",
        "de optimizacion, relacion con los esquemas bÃÅasicos de regresion discutidos en el anterior ejercicio y tambien su escalabilidad en caso de ser util:\n",
        "\n",
        "\n",
        "‚Ä¢ LinearRegresor\n",
        "‚Ä¢ Lasso\n",
        "‚Ä¢ ElasticNet\n",
        "‚Ä¢ KernelRidge\n",
        "‚Ä¢ SGDRegressor\n",
        "‚Ä¢ BayesianRidge\n",
        "‚Ä¢ Gaussian Process Regressor\n",
        "‚Ä¢ Support Vector Machines Regressor\n",
        "‚Ä¢ RandomForestRegressor\n",
        "\n",
        "‚Ä¢ GradientBoostingRegressor\n",
        "‚Ä¢ XGBoost\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EJ 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verificamos en que consiste y el funcionamiento principal de la librer ÃÅƒ±a RAPIDS. Posteriormente, se elabora una tabla que compara\n",
        "los metodos e hiperparametros mas relevantes de los regresores mencionados en el anterior ejercicio, indicando su implementacion o el\n",
        "algoritmo equivalente disponible en RAPIDS.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EJ 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finalmente, se presenta un analisis detallado del conjunto de datos disponible en https://www.kaggle.com/competitions/nfl-big-data-bowl-2026-prediction/overview. Incluyendo la descripcion de las variables de entrada y salida, el objetivo principal del concurso, un analisis\n",
        "exploratorio basico, los procedimientos de codificacion de valores faltantes y variables categoricas, asƒ± como las estrategias de\n",
        "ingenierƒ±a de caracterƒ±sticas ‚Äîsi aplican‚Äî. Finalmente, proporcione todos los detalles necesarios para comprender, interpretar y\n",
        "analizar adecuadamente el conjunto de datos.\n",
        "Luego, utilizando un esquema de validacion hold-out con una partici  ÃÅon del 60 % para entrenamiento, 20 % para validacion y 20 %\n",
        "para evaluacion del rendimiento, compare los regresores mencionados en el punto 2 ‚Äîconsiderando sus posibles implementacio-\n",
        "nes en RAPIDS, segun lo indicado en el punto 3‚Äî, empleando el conjunto de datos de entrenamiento disponible en el dataset.\n",
        "Realice las consideraciones necesarias para la implementacion y sintonizacion de cada modelo mediante optimizacion bayesiana,\n",
        "con el fin de determinar los hiperparametros mas relevantes de cada algoritmo. Justifique la seleccion de los hiperparametros a\n",
        "optimizar, asƒ± como la rejilla o los rangos de valores definidos para cada modelo, de acuerdo con las caracterƒ±sticas estudiadas\n",
        "y el score a minimizar. Finalmente, presente los rendimientos promedio obtenidos sobre el conjunto de evaluacion, junto con su\n",
        "respectiva desviacion est ÃÅandar, empleando las siguientes metricas de desempeno: MAE, MSE, R2 y MAPE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### entorno de desarrollo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "primero es necesario configurar nuestro  entorno, comenzando por la importancion de las librerias y dependencias necesarias para este caso, una vez instaladas en el entorno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import gdown \n",
        "import zipfile \n",
        "import pandas as pd                         \n",
        "from scipy import stats\n",
        "# Set the default style for seaborn\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")      \n",
        "\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.display import display, Image\n",
        "import sklearn \n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "es importante configurar matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "tambi√©n, creamos una carpeta para guardar los resultados y otra para la importaci√≥n de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "carpetas creadas en el entorno de trabajo\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "try:\n",
        "  os.mkdir('results')\n",
        "  os.mkdir('data')\n",
        "  print('carpetas creadas en el entorno de trabajo')\n",
        "except:\n",
        "  print(\"Carpeta results ya existe\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "finalmente, los warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings \n",
        "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  importaci√≥n y lectura  de los datos: \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### usaremos gdown para descargar desde el drive personal (evitando conflictos de permiso) y procederemos con zip file para descomprimir el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1dqeoLxOrYAf0-JS2sf5sDHxxIRuX8PjG\n",
            "From (redirected): https://drive.google.com/uc?id=1dqeoLxOrYAf0-JS2sf5sDHxxIRuX8PjG&confirm=t&uuid=f4c6e820-00cb-4d98-bc93-0e42c57d388b\n",
            "To: a:\\wnOs\\LR\\machineLearningTheoryEnv\\TAM\\devEnv\\MLT_LR\\PYDevEnv\\devContent\\tests\\P1\\data\\NFLdataset.zip\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 107M/107M [00:02<00:00, 46.6MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Volume in drive A is dataOs\n",
            " Volume Serial Number is 42ED-9D11\n",
            "\n",
            " Directory of a:\\wnOs\\LR\\machineLearningTheoryEnv\\TAM\\devEnv\\MLT_LR\\PYDevEnv\\devContent\\tests\\P1\n",
            "\n",
            "16/10/2025  10:05    <DIR>          .\n",
            "16/10/2025  09:50    <DIR>          ..\n",
            "16/10/2025  10:06            10,420 basis.ipynb\n",
            "16/10/2025  10:06    <DIR>          data\n",
            "16/10/2025  09:50    <DIR>          docs\n",
            "14/10/2025  22:56             4,611 README.md\n",
            "16/10/2025  09:54    <DIR>          results\n",
            "               2 File(s)         15,031 bytes\n",
            "               5 Dir(s)  579,924,164,608 bytes free\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Download dataset from personal Google Drive\n",
        "\n",
        "# https://drive.google.com/file/d/1dqeoLxOrYAf0-JS2sf5sDHxxIRuX8PjG/view?usp=sharing\n",
        "fileID = \"1dqeoLxOrYAf0-JS2sf5sDHxxIRuX8PjG\"\n",
        "url = f\"https://drive.google.com/uc?id={fileID}\"\n",
        "output = \"data/NFLdataset.zip\"\n",
        "gdown.download(url, output, quiet=False, fuzzy=True, use_cookies=False)\n",
        "  \n",
        "!dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### procedemos descomprimiendo el dataset descargado mediante drive usando ZIPFILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' second version \\nimport shutil\\nshutil.unpack_archive(\"dataset.zip\", \"ExtractedDataset\", \"zip\")\\n'"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with zipfile.ZipFile(\"data/NFLdataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"data/ExtractedDataset\")\n",
        "\n",
        "''' second version \n",
        "import shutil\n",
        "shutil.unpack_archive(\"dataset.zip\", \"ExtractedDataset\", \"zip\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "es importante recoerdar ignorar estas carpetas en nuestro .gitignore "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### una vez con el dataset extra√≠do procedemos a realizar la lectura del csv usando pandas o cuDF\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# END NB\n",
        "Cristhian Mateo Almeida G√≥mez\n",
        "\n",
        "\n",
        "\n",
        "presentado al profesor Andr√©s Marino Alvarez Meza. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "DevelopTamEnv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
